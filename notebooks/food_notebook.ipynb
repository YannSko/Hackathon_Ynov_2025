{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Food API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Define your product search term\n",
    "product_name = \"raisin\"\n",
    "search_url = \"https://world.openfoodfacts.org/cgi/search.pl\"\n",
    "\n",
    "# Parameters for the API request\n",
    "params = {\n",
    "    \"search_terms\": product_name,\n",
    "    \"search_simple\": 1,\n",
    "    \"json\": 1,\n",
    "    \"page_size\": 5,  # Limit the number of results for performance\n",
    "}\n",
    "\n",
    "# Make the request\n",
    "response = requests.get(search_url, params=params)\n",
    "\n",
    "# Process the results\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    if data.get(\"products\"):\n",
    "        print(f\"Found {len(data['products'])} products matching '{product_name}':\\n\")\n",
    "        print(\"Full JSON response for all products:\\n\")\n",
    "        # Print the full JSON response for all matching products\n",
    "        for product in data[\"products\"]:\n",
    "            print(product)  # Print the full product JSON\n",
    "    else:\n",
    "        print(\"No products found for your search term.\")\n",
    "else:\n",
    "    print(f\"Failed to retrieve data. HTTP Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Define your product search term\n",
    "product_name = \"Muesli Raisin, Figue, Abricot\"\n",
    "search_url = \"https://world.openfoodfacts.org/cgi/search.pl\"\n",
    "\n",
    "# Parameters for the API request\n",
    "params = {\n",
    "    \"search_terms\": product_name,\n",
    "    \"search_simple\": 1,\n",
    "    \"json\": 1,\n",
    "    \"page_size\": 1,  # Limit results for simplicity\n",
    "}\n",
    "\n",
    "# Make the request\n",
    "response = requests.get(search_url, params=params)\n",
    "\n",
    "# Process the results\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    if data.get(\"products\"):\n",
    "        product = data[\"products\"][0]  # Take the first product\n",
    "        product_name = product.get(\"product_name\", \"Unknown Product\")\n",
    "        barcode = product.get(\"code\", \"N/A\")\n",
    "        carbon_footprint_100g = product.get(\"carbon_footprint_100g\", None)\n",
    "        carbon_footprint_debug = product.get(\"carbon_footprint_from_known_ingredients_debug\", None)\n",
    "        agribalyse_co2_total = product.get(\"agribalyse\", {}).get(\"co2_total\", None)\n",
    "\n",
    "        print(f\"Product Name: {product_name}\")\n",
    "        print(f\"Barcode: {barcode}\")\n",
    "        \n",
    "        # Display carbon footprint information\n",
    "        if carbon_footprint_100g:\n",
    "            print(f\"Carbon Footprint (per 100g): {carbon_footprint_100g} g CO₂e\")\n",
    "        elif agribalyse_co2_total:\n",
    "            print(f\"Agribalyse Total CO₂ Emissions: {agribalyse_co2_total} kg CO₂e\")\n",
    "        elif carbon_footprint_debug:\n",
    "            print(f\"Estimated Carbon Footprint (from ingredients): {carbon_footprint_debug}\")\n",
    "        else:\n",
    "            print(\"Carbon Footprint data is not available.\")\n",
    "    else:\n",
    "        print(\"No products found for your search term.\")\n",
    "else:\n",
    "    print(f\"Failed to retrieve data. HTTP Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Agribalyse data\n",
    "import pandas as pd\n",
    "\n",
    "file_path = '../data/agribalyse-31-detail-par-ingredient.csv'\n",
    "agribalyse_data = pd.read_csv(file_path)\n",
    "\n",
    "# Search for a product by name or category\n",
    "search_term = \"Muesli\"\n",
    "matched_products = agribalyse_data[agribalyse_data[\"Nom Français\"].str.contains(search_term, case=False, na=False)]\n",
    "\n",
    "# If matches are found, calculate carbon footprint\n",
    "if not matched_products.empty:\n",
    "    print(f\"Found {len(matched_products)} matches in Agribalyse for '{search_term}':\")\n",
    "    for _, product in matched_products.iterrows():\n",
    "        product_name = product[\"Nom Français\"]\n",
    "        carbon_footprint_per_kg = product[\"Changement climatique\"]\n",
    "        weight_kg = 0.250  # Example: 250g\n",
    "        carbon_footprint = carbon_footprint_per_kg * weight_kg\n",
    "        print(f\"- {product_name}: {carbon_footprint:.2f} kg CO₂e for 250g\")\n",
    "else:\n",
    "    print(f\"No matches found for '{search_term}' in Agribalyse.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install unidecode\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import unidecode\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "# Chemin vers le fichier Agribalyse\n",
    "file_path = \"../data/agribalyse-31-detail-par-ingredient.csv\"\n",
    "agribalyse_data = pd.read_csv(file_path)\n",
    "\n",
    "def search_in_agribalyse_with_similarity(search_term, weight_kg):\n",
    "\n",
    "    from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "    # Combine French and English stopwords\n",
    "    french_stopwords = set(stopwords.words(\"french\")) | ENGLISH_STOP_WORDS\n",
    "    \n",
    "    # Normalize data\n",
    "    agribalyse_data[\"Nom Français\"] = (\n",
    "        agribalyse_data[\"Nom Français\"].str.strip().str.lower().apply(unidecode.unidecode)\n",
    "    )\n",
    "    search_term = unidecode.unidecode(search_term.strip().lower())\n",
    "\n",
    "    # Prepare data\n",
    "    product_names = agribalyse_data[\"Nom Français\"].dropna().tolist()\n",
    "    product_names.append(search_term)\n",
    "\n",
    "    # Vectorize\n",
    "    stop_words_list = list(french_stopwords)\n",
    "\n",
    "    # Vectorize\n",
    "    vectorizer = TfidfVectorizer(analyzer=\"word\", ngram_range=(1, 2), stop_words=stop_words_list)\n",
    "    tfidf_matrix = vectorizer.fit_transform(product_names)\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    similarities = cosine_similarity(tfidf_matrix[-1], tfidf_matrix[:-1])[0]\n",
    "    best_match_index = similarities.argmax()\n",
    "    best_match_score = similarities[best_match_index]\n",
    "    best_match_product = agribalyse_data.iloc[best_match_index]\n",
    "\n",
    "    # Debugging outputs\n",
    "    print(\"Top 5 Similarity Scores and Matches:\")\n",
    "    top_indices = similarities.argsort()[-5:][::-1]\n",
    "    for idx in top_indices:\n",
    "        match_name = agribalyse_data.iloc[idx][\"Nom Français\"]\n",
    "        score = similarities[idx]\n",
    "        print(f\" - {match_name}: {score:.2f}\")\n",
    "\n",
    "    if best_match_score > 0.15:  # Lower threshold\n",
    "        product_name = best_match_product[\"Nom Français\"]\n",
    "        carbon_footprint_per_kg = best_match_product[\"Changement climatique\"]\n",
    "        carbon_footprint = carbon_footprint_per_kg * weight_kg\n",
    "        print(f\"- Closest match in Agribalyse: {product_name} (Similarity: {best_match_score:.2f})\")\n",
    "        print(f\"  Carbon Footprint: {carbon_footprint:.2f} kg CO₂e for {weight_kg * 1000:.0f}g\")\n",
    "    else:\n",
    "        print(f\"No sufficiently similar products found for '{search_term}'.\")\n",
    "\n",
    "\n",
    "\n",
    "# Fonction pour chercher dans l'API Open Food Facts\n",
    "def search_in_open_food_facts(product_name, weight_kg):\n",
    "    search_url = \"https://world.openfoodfacts.org/cgi/search.pl\"\n",
    "    params = {\n",
    "        \"search_terms\": product_name,\n",
    "        \"search_simple\": 1,\n",
    "        \"json\": 1,\n",
    "        \"page_size\": 1,\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(search_url, params=params, timeout=5)  # Timeout de 5 secondes\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            if data.get(\"products\"):\n",
    "                product = data[\"products\"][0]  # Prendre le premier produit\n",
    "                product_name = product.get(\"product_name\", \"Unknown Product\")\n",
    "                carbon_footprint_100g = product.get(\"carbon_footprint_100g\", None)\n",
    "                agribalyse_co2_total = product.get(\"agribalyse\", {}).get(\"co2_total\", None)\n",
    "                \n",
    "                print(f\"Product Name: {product_name}\")\n",
    "                if carbon_footprint_100g:\n",
    "                    carbon_footprint = (float(carbon_footprint_100g) / 100) * weight_kg * 1000\n",
    "                    print(f\"Carbon Footprint (per {weight_kg * 1000:.0f}g): {carbon_footprint:.2f} g CO₂e\")\n",
    "                elif agribalyse_co2_total:\n",
    "                    carbon_footprint = float(agribalyse_co2_total) * weight_kg\n",
    "                    print(f\"Agribalyse Total CO₂ Emissions: {carbon_footprint:.2f} kg CO₂e\")\n",
    "                else:\n",
    "                    print(\"Carbon Footprint data is not available in Open Food Facts.\")\n",
    "            else:\n",
    "                print(\"No products found for your search term in Open Food Facts.\")\n",
    "                print(\"Switching to Agribalyse...\")\n",
    "                search_in_agribalyse_with_similarity(product_name, weight_kg)\n",
    "        else:\n",
    "            print(f\"Failed to retrieve data from Open Food Facts. HTTP Status: {response.status_code}\")\n",
    "            print(\"Switching to Agribalyse...\")\n",
    "            search_in_agribalyse_with_similarity(product_name, weight_kg)\n",
    "    except requests.exceptions.Timeout:\n",
    "        print(\"Open Food Facts API timeout after 5 seconds. Switching to Agribalyse...\")\n",
    "        search_in_agribalyse_with_similarity(product_name, weight_kg)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        search_in_agribalyse_with_similarity(product_name, weight_kg)\n",
    "\n",
    "# Nom du produit et poids (exemple : 250g)\n",
    "product_name = \"muesli\"\n",
    "weight_kg = 0.250  # 250g\n",
    "\n",
    "# Chercher dans Open Food Facts avec fallback sur Agribalyse\n",
    "search_in_open_food_facts(product_name, weight_kg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import unidecode\n",
    "\n",
    "# Load Agribalyse datasets\n",
    "datasets = {\n",
    "    \"par_etape\": \"../data/agribalyse-31-detail-par-etape.csv\",\n",
    "    \"par_ingredient\": \"../data/agribalyse-31-detail-par-ingredient.csv\",\n",
    "    \"synthese\": \"../data/agribalyse-31-synthese.csv\"\n",
    "}\n",
    "\n",
    "# Define the correct column mappings\n",
    "column_mappings = {\n",
    "    \"par_etape\": \"Nom du Produit en Français\",\n",
    "    \"par_ingredient\": \"Nom Français\",\n",
    "    \"synthese\": \"Nom du Produit en Français\"\n",
    "}\n",
    "\n",
    "agribalyse_data = {key: pd.read_csv(path) for key, path in datasets.items()}\n",
    "\n",
    "\n",
    "def normalize_text(text):\n",
    "    \"\"\"Normalize text by removing accents and converting to lowercase.\"\"\"\n",
    "    return unidecode.unidecode(text.strip().lower())\n",
    "\n",
    "\n",
    "def filter_meaningful_components(components):\n",
    "    \"\"\"Filter out common stopwords and retain meaningful components.\"\"\"\n",
    "    french_stopwords = {\"de\", \"et\", \"aux\", \"pour\", \"avec\", \"sur\", \"au\"}  # Extend as needed\n",
    "    return [component for component in components if component not in french_stopwords]\n",
    "\n",
    "\n",
    "def search_in_dataset_with_similarity(dataset, column_name, search_term, weight_kg):\n",
    "    \"\"\"Search in a specific Agribalyse dataset with cosine similarity.\"\"\"\n",
    "    # Normalize data\n",
    "    dataset[column_name] = dataset[column_name].str.strip().str.lower().apply(unidecode.unidecode)\n",
    "    search_term = normalize_text(search_term)\n",
    "\n",
    "    # Prepare data\n",
    "    product_names = dataset[column_name].dropna().tolist()\n",
    "    product_names.append(search_term)\n",
    "\n",
    "    # Vectorize\n",
    "    vectorizer = TfidfVectorizer(analyzer=\"word\", ngram_range=(1, 2), stop_words=\"english\")\n",
    "    tfidf_matrix = vectorizer.fit_transform(product_names)\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    similarities = cosine_similarity(tfidf_matrix[-1], tfidf_matrix[:-1])[0]\n",
    "    best_match_index = similarities.argmax()\n",
    "    best_match_score = similarities[best_match_index]\n",
    "    best_match_product = dataset.iloc[best_match_index]\n",
    "\n",
    "    # Debugging outputs\n",
    "    print(f\"Top 5 Similarity Scores and Matches in {column_name}:\")\n",
    "    top_indices = similarities.argsort()[-5:][::-1]\n",
    "    for idx in top_indices:\n",
    "        match_name = dataset.iloc[idx][column_name]\n",
    "        score = similarities[idx]\n",
    "        print(f\" - {match_name}: {score:.2f}\")\n",
    "\n",
    "    if best_match_score > 0.2:  # Threshold for similarity\n",
    "        product_name = best_match_product[column_name]\n",
    "        carbon_footprint_per_kg = best_match_product[\"Changement climatique\"]\n",
    "        carbon_footprint = carbon_footprint_per_kg * weight_kg\n",
    "        print(f\"- Closest match in dataset: {product_name} (Similarity: {best_match_score:.2f})\")\n",
    "        print(f\"  Carbon Footprint: {carbon_footprint:.2f} kg CO₂e for {weight_kg * 1000:.0f}g\")\n",
    "    else:\n",
    "        print(f\"No sufficiently similar products found for '{search_term}' in this dataset.\")\n",
    "\n",
    "\n",
    "def search_in_all_datasets(search_term, weight_kg):\n",
    "    \"\"\"Search across all Agribalyse datasets.\"\"\"\n",
    "    for key, dataset in agribalyse_data.items():\n",
    "        column_name = column_mappings[key]\n",
    "        print(f\"\\nSearching in dataset: {key.upper()}...\")\n",
    "        try:\n",
    "            search_in_dataset_with_similarity(dataset, column_name, search_term, weight_kg)\n",
    "        except KeyError:\n",
    "            print(f\"KeyError: The column '{column_name}' does not exist in the dataset {key}.\")\n",
    "\n",
    "\n",
    "def search_in_open_food_facts(product_name, weight_kg):\n",
    "    \"\"\"Search in Open Food Facts and fallback to Agribalyse if needed.\"\"\"\n",
    "    search_url = \"https://world.openfoodfacts.org/cgi/search.pl\"\n",
    "    params = {\n",
    "        \"search_terms\": product_name,\n",
    "        \"search_simple\": 1,\n",
    "        \"json\": 1,\n",
    "        \"page_size\": 1,\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(search_url, params=params, timeout=5)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            if data.get(\"products\"):\n",
    "                product = data[\"products\"][0]\n",
    "                product_name = product.get(\"product_name\", \"Unknown Product\")\n",
    "                carbon_footprint_100g = product.get(\"carbon_footprint_100g\", None)\n",
    "\n",
    "                print(f\"Product Name: {product_name}\")\n",
    "                if carbon_footprint_100g:\n",
    "                    carbon_footprint = (float(carbon_footprint_100g) / 100) * weight_kg * 1000\n",
    "                    print(f\"Carbon Footprint (per {weight_kg * 1000:.0f}g): {carbon_footprint:.2f} g CO₂e\")\n",
    "                else:\n",
    "                    print(\"Carbon Footprint data is not available in Open Food Facts.\")\n",
    "                    print(\"Switching to Agribalyse with all datasets...\")\n",
    "                    search_in_all_datasets(product_name, weight_kg)\n",
    "            else:\n",
    "                print(\"No products found for your search term in Open Food Facts.\")\n",
    "                print(\"Switching to Agribalyse...\")\n",
    "                search_in_all_datasets(product_name, weight_kg)\n",
    "        else:\n",
    "            print(f\"Failed to retrieve data from Open Food Facts. HTTP Status: {response.status_code}\")\n",
    "            print(\"Switching to Agribalyse...\")\n",
    "            search_in_all_datasets(product_name, weight_kg)\n",
    "    except requests.exceptions.Timeout:\n",
    "        print(\"Open Food Facts API timeout after 5 seconds. Switching to Agribalyse...\")\n",
    "        search_in_all_datasets(product_name, weight_kg)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        search_in_all_datasets(product_name, weight_kg)\n",
    "\n",
    "\n",
    "# Test Input\n",
    "product_name = \"soda à l'orange\"\n",
    "weight_kg = 1  # 1 kg\n",
    "search_in_open_food_facts(product_name, weight_kg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carbon Footprint data is not available in Open Food Facts.\n",
      "No products found in Open Food Facts.\n",
      "Switching to Agribalyse with all datasets...\n",
      "Searching for component: Fanta...\n",
      "Searching for component: Orange...\n",
      "Searching for component: 2ltr...\n",
      "Final Result: Fanta Orange 2ltr - 0.12 kg CO₂e\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import unidecode\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Load Agribalyse datasets\n",
    "datasets = {\n",
    "    \"par_etape\": \"../data/agribalyse-31-detail-par-etape.csv\",\n",
    "    \"par_ingredient\": \"../data/agribalyse-31-detail-par-ingredient.csv\",\n",
    "    \"synthese\": \"../data/agribalyse-31-synthese.csv\"\n",
    "}\n",
    "\n",
    "# Define the correct column mappings\n",
    "column_mappings = {\n",
    "    \"par_etape\": \"Nom du Produit en Français\",\n",
    "    \"par_ingredient\": \"Nom Français\",\n",
    "    \"synthese\": \"Nom du Produit en Français\"\n",
    "}\n",
    "\n",
    "# Load datasets into memory\n",
    "agribalyse_data = {key: pd.read_csv(path) for key, path in datasets.items()}\n",
    "\n",
    "# Pre-define vectorizer\n",
    "vectorizer = TfidfVectorizer(analyzer=\"word\", ngram_range=(1, 2), stop_words=\"english\")\n",
    "\n",
    "# Caching setup\n",
    "CACHE_FILE = \"open_food_facts_cache.json\"\n",
    "if os.path.exists(CACHE_FILE):\n",
    "    with open(CACHE_FILE, \"r\") as f:\n",
    "        cache = json.load(f)\n",
    "else:\n",
    "    cache = {}\n",
    "\n",
    "\n",
    "def save_cache():\n",
    "    \"\"\"Save cache to file.\"\"\"\n",
    "    with open(CACHE_FILE, \"w\") as f:\n",
    "        json.dump(cache, f)\n",
    "\n",
    "\n",
    "def normalize_text(text):\n",
    "    \"\"\"Normalize text by removing accents and converting to lowercase.\"\"\"\n",
    "    return unidecode.unidecode(text.strip().lower())\n",
    "\n",
    "\n",
    "def filter_meaningful_components(components):\n",
    "    \"\"\"Filter out common stopwords and retain meaningful components.\"\"\"\n",
    "    french_stopwords = {\"de\", \"et\", \"aux\", \"pour\", \"avec\", \"sur\", \"au\"}  # Extend as needed\n",
    "    return [component for component in components if component not in french_stopwords]\n",
    "\n",
    "\n",
    "def search_in_dataset_with_similarity(dataset, column_name, search_term, weight_kg):\n",
    "    \"\"\"Search in a specific Agribalyse dataset with cosine similarity.\"\"\"\n",
    "    # Copy and normalize the dataset column\n",
    "    normalized_column = dataset[column_name].dropna().str.strip().str.lower().apply(unidecode.unidecode)\n",
    "    search_term = normalize_text(search_term)\n",
    "\n",
    "    # Prepare data for vectorization\n",
    "    product_names = normalized_column.tolist()\n",
    "    product_names.append(search_term)\n",
    "\n",
    "    # Vectorize and calculate cosine similarity\n",
    "    tfidf_matrix = vectorizer.fit_transform(product_names)\n",
    "    similarities = cosine_similarity(tfidf_matrix[-1], tfidf_matrix[:-1])[0]\n",
    "\n",
    "    # Get the best match\n",
    "    best_match_index = similarities.argmax()\n",
    "    best_match_score = similarities[best_match_index]\n",
    "\n",
    "    # Handle results\n",
    "    if best_match_score > 0.2:  # Threshold for similarity\n",
    "        best_match_product = dataset.iloc[best_match_index]\n",
    "        product_name = best_match_product[column_name]\n",
    "        carbon_footprint_per_kg = best_match_product.get(\"Changement climatique\", 0)\n",
    "        carbon_footprint = carbon_footprint_per_kg * weight_kg\n",
    "        return {\"product_name\": product_name, \"carbon_footprint\": carbon_footprint}\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def search_in_all_datasets(search_term, weight_kg):\n",
    "    \"\"\"Search across all Agribalyse datasets.\"\"\"\n",
    "    results = []\n",
    "    for key, dataset in agribalyse_data.items():\n",
    "        column_name = column_mappings[key]\n",
    "        try:\n",
    "            result = search_in_dataset_with_similarity(dataset, column_name, search_term, weight_kg)\n",
    "            if result:\n",
    "                results.append(result)\n",
    "        except KeyError:\n",
    "            print(f\"KeyError: The column '{column_name}' does not exist in the dataset {key}.\")\n",
    "    return results\n",
    "\n",
    "\n",
    "def search_in_open_food_facts(product_name, weight_kg):\n",
    "    \"\"\"Search in Open Food Facts and fallback to Agribalyse if needed.\"\"\"\n",
    "    # Check cache first\n",
    "    if product_name in cache:\n",
    "        print(f\"Using cached data for '{product_name}'...\")\n",
    "        return cache[product_name]\n",
    "\n",
    "    # API Request\n",
    "    search_url = \"https://world.openfoodfacts.org/cgi/search.pl\"\n",
    "    params = {\n",
    "        \"search_terms\": product_name,\n",
    "        \"search_simple\": 1,\n",
    "        \"json\": 1,\n",
    "        \"page_size\": 1,\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(search_url, params=params, timeout=5)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            if data.get(\"products\"):\n",
    "                product = data[\"products\"][0]\n",
    "                product_name = product.get(\"product_name\", \"Unknown Product\")\n",
    "                carbon_footprint_100g = product.get(\"carbon_footprint_100g\", None)\n",
    "\n",
    "                if carbon_footprint_100g:\n",
    "                    carbon_footprint = (float(carbon_footprint_100g) / 100) * weight_kg * 1000\n",
    "                    result = {\"product_name\": product_name, \"carbon_footprint\": carbon_footprint}\n",
    "                    cache[product_name] = result\n",
    "                    save_cache()\n",
    "                    return result\n",
    "                else:\n",
    "                    print(\"Carbon Footprint data is not available in Open Food Facts.\")\n",
    "\n",
    "        print(\"No products found in Open Food Facts.\")\n",
    "    except requests.exceptions.Timeout:\n",
    "        print(\"Open Food Facts API timeout after 5 seconds.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "    # Fallback to Agribalyse\n",
    "    print(\"Switching to Agribalyse with all datasets...\")\n",
    "    components = filter_meaningful_components(product_name.split())\n",
    "    results = []\n",
    "    for component in components:\n",
    "        print(f\"Searching for component: {component}...\")\n",
    "        component_results = search_in_all_datasets(component, weight_kg)\n",
    "        results.extend(component_results)\n",
    "\n",
    "    if results:\n",
    "        # Calculate the mean carbon footprint\n",
    "        total_footprint = sum(r[\"carbon_footprint\"] for r in results)\n",
    "        mean_footprint = total_footprint / len(results)\n",
    "        final_result = {\"product_name\": product_name, \"carbon_footprint\": mean_footprint}\n",
    "        cache[product_name] = final_result\n",
    "        save_cache()\n",
    "        return final_result\n",
    "\n",
    "    return {\"product_name\": product_name, \"carbon_footprint\": None}\n",
    "\n",
    "\n",
    "# Test Input\n",
    "product_name = \"soda à l'orange\"\n",
    "weight_kg = 0.5  # 1 kg\n",
    "result = search_in_open_food_facts(product_name, weight_kg)\n",
    "if result[\"carbon_footprint\"] is not None:\n",
    "    print(f\"Final Result: {result['product_name']} - {result['carbon_footprint']:.2f} kg CO₂e\")\n",
    "else:\n",
    "    print(f\"No carbon footprint data available for '{product_name}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-20 20:13:31,372 [INFO]: No products found in Open Food Facts.\n",
      "2025-01-20 20:13:31,374 [INFO]: Switching to Agribalyse datasets...\n",
      "2025-01-20 20:13:31,375 [INFO]: Searching for component: Chips...\n",
      "2025-01-20 20:13:31,383 [INFO]: Searching for component: saveur...\n",
      "2025-01-20 20:13:31,387 [INFO]: Searching for component: Poulet...\n",
      "2025-01-20 20:13:31,390 [INFO]: Searching for component: Braisé...\n",
      "2025-01-20 20:13:31,395 [INFO]: Final Result: Chips saveur Poulet Braisé - 2.64 kg CO₂e\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import unidecode\n",
    "import os\n",
    "import json\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import logging\n",
    "\n",
    "# Logging setup\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s [%(levelname)s]: %(message)s\")\n",
    "\n",
    "# Load Agribalyse datasets\n",
    "datasets = {\n",
    "    \"par_etape\": \"../data/agribalyse-31-detail-par-etape.csv\",\n",
    "    \"par_ingredient\": \"../data/agribalyse-31-detail-par-ingredient.csv\",\n",
    "    \"synthese\": \"../data/agribalyse-31-synthese.csv\"\n",
    "}\n",
    "\n",
    "column_mappings = {\n",
    "    \"par_etape\": \"Nom du Produit en Français\",\n",
    "    \"par_ingredient\": \"Nom Français\",\n",
    "    \"synthese\": \"Nom du Produit en Français\"\n",
    "}\n",
    "\n",
    "agribalyse_data = {key: pd.read_csv(path) for key, path in datasets.items()}\n",
    "\n",
    "# Precompute TF-IDF for datasets\n",
    "vectorizer = TfidfVectorizer(analyzer=\"word\", ngram_range=(1, 2), stop_words=\"english\")\n",
    "vocabulary = None\n",
    "precomputed_tfidf = {}\n",
    "\n",
    "for key, dataset in agribalyse_data.items():\n",
    "    column_name = column_mappings[key]\n",
    "    dataset[column_name] = dataset[column_name].dropna().str.strip().str.lower().apply(unidecode.unidecode)\n",
    "    \n",
    "    if vocabulary is None:\n",
    "        # Fit the vectorizer on the first dataset and save the vocabulary\n",
    "        tfidf_matrix = vectorizer.fit_transform(dataset[column_name].tolist())\n",
    "        vocabulary = vectorizer.vocabulary_\n",
    "    else:\n",
    "        # Use the same vocabulary for other datasets\n",
    "        temp_vectorizer = TfidfVectorizer(analyzer=\"word\", ngram_range=(1, 2), stop_words=\"english\", vocabulary=vocabulary)\n",
    "        tfidf_matrix = temp_vectorizer.fit_transform(dataset[column_name].tolist())\n",
    "    \n",
    "    precomputed_tfidf[key] = {\"matrix\": tfidf_matrix, \"names\": dataset[column_name]}\n",
    "\n",
    "# Caching setup\n",
    "CACHE_FILE = \"open_food_facts_cache.json\"\n",
    "if os.path.exists(CACHE_FILE):\n",
    "    with open(CACHE_FILE, \"r\") as f:\n",
    "        cache = json.load(f)\n",
    "else:\n",
    "    cache = {}\n",
    "\n",
    "\n",
    "def save_cache():\n",
    "    \"\"\"Save cache to file.\"\"\"\n",
    "    with open(CACHE_FILE, \"w\") as f:\n",
    "        json.dump(cache, f)\n",
    "\n",
    "\n",
    "def normalize_text(text):\n",
    "    \"\"\"Normalize text by removing accents and converting to lowercase.\"\"\"\n",
    "    return unidecode.unidecode(text.strip().lower())\n",
    "\n",
    "\n",
    "def filter_meaningful_components(components):\n",
    "    \"\"\"Filter out common stopwords and retain meaningful components.\"\"\"\n",
    "    french_stopwords = {\"de\", \"et\", \"aux\", \"pour\", \"avec\", \"sur\", \"au\"}\n",
    "    return [component for component in components if component not in french_stopwords]\n",
    "\n",
    "\n",
    "def search_in_dataset_with_similarity(dataset_key, search_term, weight_kg):\n",
    "    \"\"\"Search in a specific Agribalyse dataset using precomputed TF-IDF.\"\"\"\n",
    "    column_name = column_mappings[dataset_key]\n",
    "    tfidf_data = precomputed_tfidf[dataset_key]\n",
    "    tfidf_matrix = tfidf_data[\"matrix\"]\n",
    "    product_names = tfidf_data[\"names\"]\n",
    "\n",
    "    search_term_vector = vectorizer.transform([normalize_text(search_term)])\n",
    "    similarities = cosine_similarity(search_term_vector, tfidf_matrix)[0]\n",
    "\n",
    "    best_match_index = similarities.argmax()\n",
    "    best_match_score = similarities[best_match_index]\n",
    "\n",
    "    if best_match_score > 0.2:\n",
    "        best_match_product = agribalyse_data[dataset_key].iloc[best_match_index]\n",
    "        product_name = best_match_product[column_name]\n",
    "        carbon_footprint_per_kg = best_match_product.get(\"Changement climatique\", 0)\n",
    "        carbon_footprint = carbon_footprint_per_kg * weight_kg\n",
    "        return {\"product_name\": product_name, \"carbon_footprint\": carbon_footprint}\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def search_in_all_datasets(search_term, weight_kg):\n",
    "    \"\"\"Search across all Agribalyse datasets.\"\"\"\n",
    "    results = []\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = [executor.submit(search_in_dataset_with_similarity, key, search_term, weight_kg) for key in agribalyse_data]\n",
    "        for future in futures:\n",
    "            result = future.result()\n",
    "            if result:\n",
    "                results.append(result)\n",
    "    return results\n",
    "\n",
    "\n",
    "def search_in_open_food_facts(product_name, weight_kg):\n",
    "    \"\"\"Search in Open Food Facts and fallback to Agribalyse.\"\"\"\n",
    "    if product_name in cache:\n",
    "        logging.info(f\"Using cached data for '{product_name}'...\")\n",
    "        return cache[product_name]\n",
    "\n",
    "    search_url = \"https://world.openfoodfacts.org/cgi/search.pl\"\n",
    "    params = {\n",
    "        \"search_terms\": product_name,\n",
    "        \"search_simple\": 1,\n",
    "        \"json\": 1,\n",
    "        \"page_size\": 1,\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(search_url, params=params, timeout=5)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            if data.get(\"products\"):\n",
    "                product = data[\"products\"][0]\n",
    "                product_name = product.get(\"product_name\", \"Unknown Product\")\n",
    "                carbon_footprint_100g = product.get(\"carbon_footprint_100g\", None)\n",
    "\n",
    "                if carbon_footprint_100g:\n",
    "                    carbon_footprint = (float(carbon_footprint_100g) / 100) * weight_kg * 1000\n",
    "                    result = {\"product_name\": product_name, \"carbon_footprint\": carbon_footprint}\n",
    "                    cache[product_name] = result\n",
    "                    save_cache()\n",
    "                    return result\n",
    "        logging.info(\"No products found in Open Food Facts.\")\n",
    "    except requests.exceptions.Timeout:\n",
    "        logging.warning(\"Open Food Facts API timeout.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error occurred: {e}\")\n",
    "\n",
    "    # Fallback to Agribalyse\n",
    "    logging.info(\"Switching to Agribalyse datasets...\")\n",
    "    components = filter_meaningful_components(product_name.split())\n",
    "    results = []\n",
    "    for component in components:\n",
    "        logging.info(f\"Searching for component: {component}...\")\n",
    "        component_results = search_in_all_datasets(component, weight_kg)\n",
    "        results.extend(component_results)\n",
    "\n",
    "    if results:\n",
    "        total_footprint = sum(r[\"carbon_footprint\"] for r in results)\n",
    "        mean_footprint = total_footprint / len(results)\n",
    "        final_result = {\"product_name\": product_name, \"carbon_footprint\": mean_footprint}\n",
    "        cache[product_name] = final_result\n",
    "        save_cache()\n",
    "        return final_result\n",
    "\n",
    "    return {\"product_name\": product_name, \"carbon_footprint\": None}\n",
    "\n",
    "\n",
    "# Test Input\n",
    "product_name = \"pomme de terre\"\n",
    "weight_kg = 0.5\n",
    "result = search_in_open_food_facts(product_name, weight_kg)\n",
    "if result[\"carbon_footprint\"] is not None:\n",
    "    logging.info(f\"Final Result: {result['product_name']} - {result['carbon_footprint']:.2f} kg CO₂e\")\n",
    "else:\n",
    "    logging.info(f\"No carbon footprint data available for '{product_name}'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
